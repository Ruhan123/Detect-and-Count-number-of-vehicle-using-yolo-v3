{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolo_car_counting.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpI7uvfWRfoo",
        "outputId": "c8892fc3-1e83-4b87-9407-9bbafebc2c68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! wget https://pjreddie.com/media/files/yolov3.weights\n",
        "! git clone https://github.com/guptavasu1213/Yolo-Vehicle-Counter\n",
        "! mv yolov3.weights ./Yolo-Vehicle-Counter/yolo-coco/yolov3.weights\n",
        "! pip install -U opencv-python"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-27 03:16:40--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  44.5MB/s    in 5.9s    \n",
            "\n",
            "2021-05-27 03:16:46 (40.2 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n",
            "fatal: destination path 'Yolo-Vehicle-Counter' already exists and is not an empty directory.\n",
            "Requirement already up-to-date: opencv-python in /usr/local/lib/python3.7/dist-packages (4.5.2.52)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh21s__vRPS4",
        "outputId": "e68c007b-e7b9-442c-f180-428eda0c24a9"
      },
      "source": [
        "import numpy as np\n",
        "import imutils\n",
        "import time\n",
        "from scipy import spatial\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "print(cv2.__version__)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcvJXjOOAe04"
      },
      "source": [
        "def boxAndLineOverlap(x_mid_point, y_mid_point, line_coordinates):\n",
        "\tx1_line, y1_line, x2_line, y2_line = line_coordinates\n",
        "\n",
        "\tif (y_mid_point >= y1_line and y_mid_point <= y1_line+2):\n",
        "\t\treturn True\n",
        "\treturn False"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_13cVqSQ6CB"
      },
      "source": [
        "def displayVehicleCount(frame, vehicle_count):\n",
        "\tcv2.putText(\n",
        "\t\tframe, #Image\n",
        "\t\t'Detected Vehicles: ' + str(vehicle_count), #Label\n",
        "\t\t(20, 20), #Position\n",
        "\t\tcv2.FONT_HERSHEY_SIMPLEX, #Font\n",
        "\t\t0.8, #Size\n",
        "\t\t(0, 0xFF, 0), #Color\n",
        "\t\t2, #Thickness\n",
        "\t\tcv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "\t\t)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM8GYODtQ7rk"
      },
      "source": [
        "def drawDetectionBoxes(idxs, boxes, classIDs, confidences, frame):\n",
        "\t# ensure at least one detection exists\n",
        "\tif len(idxs) > 0:\n",
        "\t\t# loop over the indices we are keeping\n",
        "\t\tfor i in idxs.flatten():\n",
        "\t\t\t# extract the bounding box coordinates\n",
        "\t\t\t(x, y) = (boxes[i][0], boxes[i][1])\n",
        "\t\t\t(w, h) = (boxes[i][2], boxes[i][3])\n",
        "\n",
        "\t\t\t# draw a bounding box rectangle and label on the frame\n",
        "\t\t\tcolor = [int(c) for c in COLORS[classIDs[i]]]\n",
        "\t\t\tcv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "\t\t\ttext = \"{}: {:.4f}\".format(LABELS[classIDs[i]],\n",
        "\t\t\t\tconfidences[i])\n",
        "\t\t\tcv2.putText(frame, text, (x, y - 5),\n",
        "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\t\t\t#Draw a green dot in the middle of the box\n",
        "\t\t\tcv2.circle(frame, (x + (w//2), y+ (h//2)), 2, (0, 0xFF, 0), thickness=2)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oujg-TFEQ9rV"
      },
      "source": [
        "def initializeVideoWriter(video_width, video_height, videoStream):\n",
        "\t# Getting the fps of the source video\n",
        "\tsourceVideofps = videoStream.get(cv2.CAP_PROP_FPS)\n",
        "\t# initialize our video writer\n",
        "\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "\treturn cv2.VideoWriter(outputVideoPath, fourcc, sourceVideofps,\n",
        "\t\t(video_width, video_height), True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw9jHD7LRM5r"
      },
      "source": [
        "LABELS, USE_GPU = './Yolo-Vehicle-Counter/yolo-coco/coco.names', 1\n",
        "weightsPath, configPath = './Yolo-Vehicle-Counter/yolo-coco/yolov3.weights', './Yolo-Vehicle-Counter/yolo-coco/yolov3.cfg'\n",
        "inputVideoPath, outputVideoPath = 'my.mp4', 'out.avi'\n",
        "preDefinedConfidence, preDefinedThreshold = 0.5, 0.3\n",
        "\n",
        "list_of_vehicles = [\"bicycle\",\"car\",\"motorbike\",\"bus\",\"truck\", \"train\"]\n",
        "FRAMES_BEFORE_CURRENT = 10  \n",
        "inputWidth, inputHeight = 416, 416\n",
        "\n",
        "np.random.seed(42)\n",
        "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),\n",
        "\tdtype=\"uint8\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dUNBbNYRE6D",
        "outputId": "29b87a01-4699-4d56-ba25-db930b4ea042"
      },
      "source": [
        "print(\"[INFO] loading YOLO from disk...\")\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
        "\n",
        "#Using GPU if flag is passed\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "\n",
        "ln = net.getLayerNames()\n",
        "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# initialize the video stream, pointer to output video file, and\n",
        "# frame dimensions\n",
        "videoStream = cv2.VideoCapture(inputVideoPath)\n",
        "video_width = int(videoStream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "video_height = int(videoStream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Specifying coordinates for a default line \n",
        "x1_line = 0\n",
        "y1_line = video_height//2\n",
        "x2_line = video_width\n",
        "y2_line = video_height-50\n",
        "\n",
        "#Initialization\n",
        "previous_frame_detections = [{(0,0):0} for i in range(FRAMES_BEFORE_CURRENT)]\n",
        "# previous_frame_detections = [spatial.KDTree([(0,0)])]*FRAMES_BEFORE_CURRENT # Initializing all trees\n",
        "num_frames, vehicle_count = 0, 0\n",
        "writer = initializeVideoWriter(video_width, video_height, videoStream)\n",
        "start_time = int(time.time())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading YOLO from disk...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHnXvvsDUMNA",
        "outputId": "81d8b14e-8cfb-424d-a47c-93951376e611"
      },
      "source": [
        "for _ in tqdm(range(3334)):\n",
        "\tnum_frames+= 1\n",
        "\t# print(\"FRAME:\\t\", num_frames)\n",
        "\tboxes, confidences, classIDs = [], [], [] \n",
        "\tvehicle_crossed_line_flag = False \n",
        "\n",
        "\t# read the next frame from the file\n",
        "\t(grabbed, frame) = videoStream.read()\n",
        "\n",
        "\t# if the frame was not grabbed, then we have reached the end of the stream\n",
        "\tif not grabbed:\n",
        "\t\tbreak\n",
        "\n",
        "\t# construct a blob from the input frame and then perform a forward\n",
        "\t# pass of the YOLO object detector, giving us our bounding boxes\n",
        "\t# and associated probabilities\n",
        "\tblob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (inputWidth, inputHeight),\n",
        "\t\tswapRB=True, crop=False)\n",
        "\tnet.setInput(blob)\n",
        "\tstart = time.time()\n",
        "\tlayerOutputs = net.forward(ln)\n",
        "\tend = time.time()\n",
        "\n",
        "\t# loop over each of the layer outputs\n",
        "\tfor output in layerOutputs:\n",
        "\t\t# loop over each of the detections\n",
        "\t\tfor i, detection in enumerate(output):\n",
        "\t\t\t# extract the class ID and confidence (i.e., probability)\n",
        "\t\t\t# of the current object detection\n",
        "\t\t\tscores = detection[5:]\n",
        "\t\t\tclassID = np.argmax(scores)\n",
        "\t\t\tconfidence = scores[classID]\n",
        "\n",
        "\t\t\t# filter out weak predictions by ensuring the detected\n",
        "\t\t\t# probability is greater than the minimum probability\n",
        "\t\t\tif confidence > preDefinedConfidence:\n",
        "\t\t\t\t# scale the bounding box coordinates back relative to\n",
        "\t\t\t\t# the size of the image, keeping in mind that YOLO\n",
        "\t\t\t\t# actually returns the center (x, y)-coordinates of\n",
        "\t\t\t\t# the bounding box followed by the boxes' width and\n",
        "\t\t\t\t# height\n",
        "\t\t\t\tbox = detection[0:4] * np.array([video_width, video_height, video_width, video_height])\n",
        "\t\t\t\t(centerX, centerY, width, height) = box.astype(\"int\")\n",
        "\n",
        "\t\t\t\tif boxAndLineOverlap(centerX, centerY, (x1_line, y1_line, x2_line, y2_line)):\n",
        "\t\t\t\t\tvehicle_count += 1\n",
        "\n",
        "\t\t\t\t# use the center (x, y)-coordinates to derive the top\n",
        "\t\t\t\t# and and left corner of the bounding box\n",
        "\t\t\t\tx = int(centerX - (width / 2))\n",
        "\t\t\t\ty = int(centerY - (height / 2))\n",
        "                            \n",
        "\n",
        "\t\t\t\t# update our list of bounding box coordinates,\n",
        "\t\t\t\t# confidences, and class IDs\n",
        "\t\t\t\tboxes.append([x, y, int(width), int(height)])\n",
        "\t\t\t\tconfidences.append(float(confidence))\n",
        "\t\t\t\tclassIDs.append(classID)\n",
        "\n",
        "\tcv2.line(frame, (x1_line, y1_line), (x2_line, y2_line), (0, 0xFF, 0), 2)\n",
        "\n",
        "\t# apply non-maxima suppression to suppress weak, overlapping\n",
        "\t# bounding boxes\n",
        "\tidxs = cv2.dnn.NMSBoxes(boxes, confidences, preDefinedConfidence,\n",
        "\t\tpreDefinedThreshold)\n",
        "\n",
        "\t# Draw detection box \n",
        "\tdrawDetectionBoxes(idxs, boxes, classIDs, confidences, frame)\n",
        "\n",
        "\t# Display Vehicle Count if a vehicle has passed the line \n",
        "\tdisplayVehicleCount(frame, vehicle_count)\n",
        "\n",
        "    # write the output frame to disk\n",
        "\twriter.write(frame)\t\n",
        "\n",
        "# release the file pointers\n",
        "print(\"[INFO] cleaning up...\")\n",
        "writer.release()\n",
        "videoStream.release()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3334/3334 [59:17<00:00,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] cleaning up...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTJx5X2d25Bg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}